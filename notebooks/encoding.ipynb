{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "98576d12",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "sys.path.append(str(Path().cwd().parent))\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from matrix import are_similar\n",
        "from itertools import combinations\n",
        "from numpy import trace\n",
        "from networkx import is_bipartite\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tolerance = 1e-10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cfea9873",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_least_cell_quotient(adj_matrix):\n",
        "    \"\"\"\n",
        "    Compute the quotient matrix for the coarsest equitable partition of a graph.\n",
        "    \n",
        "    An equitable partition is a partition where the number of edges from a node\n",
        "    to cells depends only on which cell the node is in, not the specific node.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    adj_matrix : array-like\n",
        "        The adjacency matrix of the graph\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    quotient_matrix : np.ndarray\n",
        "        The quotient matrix (each entry is the number of edges between cells)\n",
        "    partition : np.ndarray\n",
        "        The partition of vertices (cell assignment for each vertex)\n",
        "    \"\"\"\n",
        "    adj = np.array(adj_matrix)\n",
        "    n = adj.shape[0]\n",
        "    \n",
        "    # 1. Start with all nodes in the same partition (color 0)\n",
        "    partition = np.zeros(n, dtype=int)\n",
        "    \n",
        "    while True:\n",
        "        # 2. For each node, create a signature based on its neighbors' partitions\n",
        "        # Signature = (current_partition, sorted_list_of_neighbor_partitions)\n",
        "        signatures = []\n",
        "        for i in range(n):\n",
        "            neighbor_parts = sorted(partition[j] for j in range(n) if adj[i, j] > 0)\n",
        "            signatures.append((partition[i], tuple(neighbor_parts)))\n",
        "        \n",
        "        # 3. Map unique signatures to new partition labels (colors)\n",
        "        unique_sigs = sorted(list(set(signatures)))\n",
        "        sig_map = {sig: idx for idx, sig in enumerate(unique_sigs)}\n",
        "        new_partition = np.array([sig_map[sig] for sig in signatures])\n",
        "        \n",
        "        # 4. If the partition hasn't changed, we've found the coarsest equitable partition\n",
        "        if np.array_equal(new_partition, partition):\n",
        "            break\n",
        "        partition = new_partition\n",
        "\n",
        "    # 5. Build the quotient matrix\n",
        "    num_cells = len(unique_sigs)\n",
        "    quotient_matrix = np.zeros((num_cells, num_cells))\n",
        "    \n",
        "    cells = [np.where(partition == i)[0] for i in range(num_cells)]\n",
        "    \n",
        "    for i in range(num_cells):\n",
        "        for j in range(num_cells):\n",
        "            # Pick any representative node 'u' from cell i\n",
        "            u = cells[i][0]\n",
        "            # Count edges from 'u' to all nodes in cell j\n",
        "            edge_count = sum(adj[u, v] for v in cells[j])\n",
        "            quotient_matrix[i, j] = edge_count\n",
        "            \n",
        "    return quotient_matrix, partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f33c7aa2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-1.79128785 -0.          2.79128785]\n",
            "\n",
            "\n",
            "[[0 0 0 0 1 1]\n",
            " [0 0 0 0 1 1]\n",
            " [0 0 0 0 1 1]\n",
            " [0 0 0 0 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-2. -0.  4.]\n",
            "\n",
            "\n",
            "[[0 0 0 1 1 0]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 0 1 1]\n",
            " [1 1 0 1 1 1]\n",
            " [1 0 1 1 1 1]\n",
            " [0 1 1 1 1 1]]\n",
            "[-1.  1.  4.]\n",
            "\n",
            "\n",
            "[[0 0 0 1 1 1]\n",
            " [0 0 0 1 1 1]\n",
            " [0 0 0 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-1.85410197 -0.          4.85410197]\n",
            "\n",
            "\n",
            "[[0 0 1 0 1 1]\n",
            " [0 0 0 1 0 1]\n",
            " [1 0 0 0 1 1]\n",
            " [0 1 0 0 0 1]\n",
            " [1 0 1 0 0 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-1.          1.38196601  3.61803399]\n",
            "\n",
            "\n",
            "[[0 0 1 1 1 1]\n",
            " [0 0 0 0 0 1]\n",
            " [1 0 0 1 1 1]\n",
            " [1 0 1 0 1 1]\n",
            " [1 0 1 1 0 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-1.          0.69722436  4.30277564]\n",
            "\n",
            "\n",
            "[[1 0 1 1 1 1]\n",
            " [0 1 1 1 1 1]\n",
            " [1 1 1 0 1 1]\n",
            " [1 1 0 1 1 1]\n",
            " [1 1 1 1 0 1]\n",
            " [1 1 1 1 1 0]]\n",
            "[-1.  1.  5.]\n",
            "\n",
            "\n",
            "[[1 0 1 1 1 1]\n",
            " [0 1 1 1 1 1]\n",
            " [1 1 0 1 1 1]\n",
            " [1 1 1 0 1 1]\n",
            " [1 1 1 1 0 1]\n",
            " [1 1 1 1 1 0]]\n",
            "[-1.  1.  5.]\n",
            "\n",
            "\n",
            "[[0 0 1 1 1 1]\n",
            " [0 0 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[-1.46410162  0.          5.46410162]\n",
            "\n",
            "\n",
            "[[1 1 1 1 1 1]\n",
            " [1 0 1 1 1 1]\n",
            " [1 1 0 1 1 1]\n",
            " [1 1 1 0 1 1]\n",
            " [1 1 1 1 0 1]\n",
            " [1 1 1 1 1 0]]\n",
            "[-1.        -0.1925824  5.1925824]\n",
            "\n",
            "\n",
            "[[1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1]\n",
            " [1 1 1 1 1 0]]\n",
            "[-0.85410197 -0.          5.85410197]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "n = 6\n",
        "\n",
        "path = f\"../graphs/graph{n}c.g6.txt\"\n",
        "f = open(path, \"r\")\n",
        "\n",
        "candidates = []\n",
        "\n",
        "for line in f:\n",
        "    g6 = line.strip()\n",
        "    G = nx.from_graph6_bytes(g6.encode())\n",
        "    A = nx.to_numpy_array(G, dtype=int)\n",
        "    # One representative per similarity class, per loop count (here 1 loop)\n",
        "    \n",
        "    for i in range(1, n):\n",
        "        for comb in combinations(range(n), i):\n",
        "            B = A.copy()\n",
        "            for j in comb:\n",
        "                B[j, j] = 1\n",
        "            eigenvalues = np.linalg.eigvalsh(B)\n",
        "            rounded_eigenvalues = np.round(eigenvalues / tolerance) * tolerance\n",
        "            unique_eigenvalues = np.unique(rounded_eigenvalues)\n",
        "\n",
        "\n",
        "            if len(unique_eigenvalues) == 3:\n",
        "                is_duplicate = any(trace(B) == trace(C) and are_similar(B, C) for C in candidates)\n",
        "                if not is_duplicate and is_bipartite(G):\n",
        "                    D = A.copy()\n",
        "                    for j in range(n):\n",
        "                        if j not in comb:\n",
        "                            D[j, j] = 1\n",
        "                    is_duplicate = any(trace(D) == trace(C) and are_similar(D, C) for C in candidates)\n",
        "                if not is_duplicate:\n",
        "                    candidates.append(B)\n",
        "                    print(B)\n",
        "                    print(unique_eigenvalues)\n",
        "                    print(\"\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8981e6d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "l_shape = []\n",
        "row_sum_candidates = []\n",
        "l_shape_row_sum_candidates = []\n",
        "others = []\n",
        "\n",
        "for candidate in candidates:\n",
        "    row_sum = np.sum(candidate, axis=1)\n",
        "    unique_row_sum = np.unique(row_sum)\n",
        "    x1, x2 = unique_row_sum if len(unique_row_sum) == 2 else (0, 0)\n",
        "    if all(row_sum == row_sum[0]):\n",
        "        row_sum_candidates.append(candidate)\n",
        "    elif len(unique_row_sum) == 2 and (x1 == n and sum(row_sum == n) == x2 or x2 == n and sum(row_sum == n) == x1):\n",
        "        l_shape.append(candidate)\n",
        "    else:\n",
        "        sub_matrix = candidate.copy()\n",
        "        mask = row_sum != n\n",
        "        sub_matrix = candidate[np.ix_(mask, mask)]\n",
        "        sub_matrix_row_sum = np.sum(sub_matrix, axis=1)\n",
        "        mask = sub_matrix_row_sum != 0\n",
        "        if all(sub_matrix_row_sum[mask] == sub_matrix_row_sum[mask][0]):\n",
        "            l_shape_row_sum_candidates.append(candidate)\n",
        "        else:\n",
        "            others.append(candidate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bd595a51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of candidates:  11\n",
            "num of row sum candidates:  2\n",
            "num of l shape candidates:  5\n",
            "num of l shape row sum candidates:  2\n",
            "num of others:  2\n"
          ]
        }
      ],
      "source": [
        "print(\"num of candidates: \", len(candidates))\n",
        "print(\"num of row sum candidates: \", len(row_sum_candidates))\n",
        "print(\"num of l shape candidates: \", len(l_shape))\n",
        "print(\"num of l shape row sum candidates: \", len(l_shape_row_sum_candidates))\n",
        "print(\"num of others: \", len(others))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6d02c13f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0]\n",
            " [0 0 0 1 0 1]\n",
            " [0 0 0 0 1 1]\n",
            " [1 1 0 1 1 1]\n",
            " [1 0 1 1 1 1]\n",
            " [0 1 1 1 1 1]]\n",
            "[2 2 2 5 5 5]\n",
            "\n",
            "\n",
            "[[0 0 1 0 1 1]\n",
            " [0 0 0 1 0 1]\n",
            " [1 0 0 0 1 1]\n",
            " [0 1 0 0 0 1]\n",
            " [1 0 1 0 0 1]\n",
            " [1 1 1 1 1 1]]\n",
            "[3 2 3 2 3 6]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for other in others:\n",
        "    print(other)\n",
        "    print(np.sum(other, axis=1))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a803a2c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate 0:\n",
            "Quotient Matrix:\n",
            " [[0 1]\n",
            " [5 1]]\n",
            "Vertex Partitions: [0 0 0 0 0 1]\n",
            "\n",
            "Candidate 1:\n",
            "Quotient Matrix:\n",
            " [[0 2]\n",
            " [4 2]]\n",
            "Vertex Partitions: [0 0 0 0 1 1]\n",
            "\n",
            "Candidate 2:\n",
            "Quotient Matrix:\n",
            " [[0 2]\n",
            " [2 3]]\n",
            "Vertex Partitions: [0 0 0 1 1 1]\n",
            "\n",
            "Candidate 3:\n",
            "Quotient Matrix:\n",
            " [[0 3]\n",
            " [3 3]]\n",
            "Vertex Partitions: [0 0 0 1 1 1]\n",
            "\n",
            "Candidate 4:\n",
            "Quotient Matrix:\n",
            " [[1 0 1]\n",
            " [0 2 1]\n",
            " [2 3 1]]\n",
            "Vertex Partitions: [1 0 1 0 1 2]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example: Compute quotient matrices for candidates\n",
        "# This creates the best/coarsest equitable partition for each adjacency matrix\n",
        "\n",
        "for idx, candidate in enumerate(candidates[:5]):  # Show first 5 examples\n",
        "    q_mat, part = get_least_cell_quotient(candidate)\n",
        "    print(f\"Candidate {idx}:\")\n",
        "    print(\"Quotient Matrix:\\n\", q_mat.astype(int))\n",
        "    print(\"Vertex Partitions:\", part)\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
